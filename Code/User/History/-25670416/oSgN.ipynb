{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficienct Object Detection with YoloV8 and KerasCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kerasCV is an extension of Keras for computer vision tasks. In this example, we're creating YoloV8 model using kerasCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/keras-team/keras-cv\n",
      "  Cloning https://github.com/keras-team/keras-cv to /tmp/pip-req-build-hx4z4d0z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/keras-team/keras-cv /tmp/pip-req-build-hx4z4d0z\n",
      "  Resolved https://github.com/keras-team/keras-cv to commit 94b0a551d03ee9de3d81663e2c1a680cb113f7f1\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from keras-cv==0.10.0) (24.1)\n",
      "Requirement already satisfied: absl-py in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from keras-cv==0.10.0) (2.1.0)\n",
      "Collecting regex (from keras-cv==0.10.0)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tensorflow-datasets (from keras-cv==0.10.0)\n",
      "  Using cached tensorflow_datasets-4.9.7-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting keras-core (from keras-cv==0.10.0)\n",
      "  Using cached keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting kagglehub (from keras-cv==0.10.0)\n",
      "  Using cached kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: requests in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from kagglehub->keras-cv==0.10.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from kagglehub->keras-cv==0.10.0) (4.67.0)\n",
      "Requirement already satisfied: numpy in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from keras-core->keras-cv==0.10.0) (1.26.4)\n",
      "Requirement already satisfied: rich in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from keras-core->keras-cv==0.10.0) (13.9.3)\n",
      "Requirement already satisfied: namex in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from keras-core->keras-cv==0.10.0) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from keras-core->keras-cv==0.10.0) (3.12.1)\n",
      "Collecting dm-tree (from keras-core->keras-cv==0.10.0)\n",
      "  Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting click (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting immutabledict (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting promise (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv==0.10.0) (5.28.3)\n",
      "Requirement already satisfied: psutil in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv==0.10.0) (6.1.0)\n",
      "Collecting pyarrow (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting simple-parsing (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached simple_parsing-0.1.6-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached tensorflow_metadata-1.16.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: termcolor in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv==0.10.0) (2.5.0)\n",
      "Collecting toml (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wrapt in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from tensorflow-datasets->keras-cv==0.10.0) (1.16.0)\n",
      "Collecting array-record>=0.5.0 (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached array_record-0.5.1-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (699 bytes)\n",
      "Collecting etils>=1.6.0 (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached etils-1.10.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv==0.10.0) (2024.10.0)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: typing_extensions in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv==0.10.0) (4.12.2)\n",
      "Collecting zipp (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from requests->kagglehub->keras-cv==0.10.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from requests->kagglehub->keras-cv==0.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from requests->kagglehub->keras-cv==0.10.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from requests->kagglehub->keras-cv==0.10.0) (2024.8.30)\n",
      "Requirement already satisfied: six in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from promise->tensorflow-datasets->keras-cv==0.10.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from rich->keras-core->keras-cv==0.10.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from rich->keras-core->keras-cv==0.10.0) (2.18.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing->tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow-datasets->keras-cv==0.10.0)\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/understressengineer/programming/env_hack/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv==0.10.0) (0.1.2)\n",
      "Using cached kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "Using cached keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached tensorflow_datasets-4.9.7-py3-none-any.whl (5.3 MB)\n",
      "Using cached array_record-0.5.1-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.2 MB)\n",
      "Using cached etils-1.10.0-py3-none-any.whl (164 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "Using cached immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m354.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading simple_parsing-0.1.6-py3-none-any.whl (112 kB)\n",
      "Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
      "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m648.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Building wheels for collected packages: keras-cv, promise\n",
      "  Building wheel for keras-cv (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-cv: filename=keras_cv-0.10.0-py3-none-any.whl size=975403 sha256=894fb490b9d4577f05221bd5100122aa08113080e5a1d8bc126ec70bebebe161\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lzlwrt77/wheels/35/f2/a0/a17d87e8d0bfd3f36a4f092213fb8f0bd8b1a87cebcec85de2\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=35eb93e63ac0b20634d1d443d36d3908711a77248a7cc99dd51d9c85f9191e82\n",
      "  Stored in directory: /home/understressengineer/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\n",
      "Successfully built keras-cv promise\n",
      "Installing collected packages: dm-tree, zipp, toml, regex, pyarrow, protobuf, promise, importlib_resources, immutabledict, etils, docstring-parser, click, tensorflow-metadata, simple-parsing, kagglehub, keras-core, array-record, tensorflow-datasets, keras-cv\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.3\n",
      "    Uninstalling protobuf-5.28.3:\n",
      "      Successfully uninstalled protobuf-5.28.3\n",
      "Successfully installed array-record-0.5.1 click-8.1.7 dm-tree-0.1.8 docstring-parser-0.16 etils-1.10.0 immutabledict-4.2.0 importlib_resources-6.4.5 kagglehub-0.3.4 keras-core-0.1.7 keras-cv-0.10.0 promise-2.3 protobuf-3.20.3 pyarrow-18.0.0 regex-2024.11.6 simple-parsing-0.1.6 tensorflow-datasets-4.9.7 tensorflow-metadata-1.16.1 toml-0.10.2 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/keras-team/keras-cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/dataset/data/annotations/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     12\u001b[0m path_annot \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/dataset/data/annotations/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get all XML file paths in path_annot and sort them\u001b[39;00m\n\u001b[1;32m     15\u001b[0m xml_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     16\u001b[0m     [\n\u001b[1;32m     17\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_annot, file_name)\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_annot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     ]\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Get all JPEG image file paths in path_images and sort them\u001b[39;00m\n\u001b[1;32m     24\u001b[0m jpg_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m     25\u001b[0m     [\n\u001b[1;32m     26\u001b[0m         os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_images, file_name)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     ]\n\u001b[1;32m     30\u001b[0m )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/dataset/data/annotations/'"
     ]
    }
   ],
   "source": [
    "class_ids = [\n",
    "    \"car\",\n",
    "    \"pedestrian\",\n",
    "    \"trafficLight\",\n",
    "    \"biker\",\n",
    "    \"truck\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "# Path to images and annotations\n",
    "path_images = \"/kaggle/input/dataset/data/images/\"\n",
    "path_annot = \"/kaggle/input/dataset/data/annotations/\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
